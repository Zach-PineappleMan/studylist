# 基于sif的长文本分段

任务目的：
输入：纯纯的长文本
输出：标题们；分段后的句子们

> 输入:是个长句子？长句子很有趣。短语才是重点。改变世界。多喝热水。
> 输出：是个长句子？长句子很有趣。\n 短语才是重点。\n 改变世界。\n 多喝热水。

已有方案：
先分成小短句，然后根据相似度直接进行合并，然后代码见 **初始方案.py** （利用了sentence_transformers的预训练模型m3e-base）
1. 分句
2. 进行编码
3. 根据相似度进行判断

可选方案：任务主题一致和语义相似度的相似度还是有差距的，所以

方案1是再进行训练，然后增加分段为几段（设置参数，使得分段结果再按照一定依据进行再次合并），等等。

方案2是换另一个方法，不仅仅是是文本相似度，可以考虑更多（比如主谓宾这些结构化的东西，例如一个句子缺少主语，就直接和前一句是一段的，或者是感叹词啥的，不单独为一段）等等。

下面是参考项目

## 参考项目：

<https://github.com/DeqianBai/Automatically-extract-news-person-speech/tree/master>
 
项目步骤：

1. 分句
2. 句子依存分析
   - 构建依存树
   - 查找说话的实体和内容
     - 查找说话实体：状中结构查找实体
     - 获取实体说的话
3. 根据句子相似度进行判断
4. 低于某个阈值则判定为结束

## 改编后：
将任意长文本进行分段。

1. 分句（不变）
2. 进行编码（SIF方法）
3. 计算句子间的相似度，并从上下句相似度最低的地方砍一刀（2、4、8可以递归？）
4. 合并
   据句子相似度进行判断
6. 进行输出
